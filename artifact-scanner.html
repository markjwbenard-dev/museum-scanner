<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Denman Island Museum Artifact Scanner</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background: linear-gradient(135deg, #1a1a1a 0%, #2c2c2c 100%);
            color: #ffffff;
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            overflow-x: hidden;
        }
        .container {
            background: #252525;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
            max-width: 500px;
            width: 90%;
            text-align: center;
        }
        h1 {
            font-size: 1.8rem;
            margin-bottom: 10px;
            color: #baa597; /* Blue slate */
            padding: 35px; /* Added padding for image bg */
            background-image: url('https://denmanmuseum.ca/wp-content/uploads/2020/04/2020_04_05_14_01_050008-1024x759.jpg'); /* Stone texture */
            background-size: cover;
            background-position: center;
            border-radius: 8px;
            position: relative;
            overflow: hidden;
        }
        h1::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.5); /* Overlay for readability */
            z-index: 1;
        }
        h1 span {
            position: relative;
            z-index: 2; /* Text above overlay */
        }
        p {
            font-size: 1rem;
            color: #cccccc;
            margin-bottom: 20px;
        }
        video {
            width: 100%;
            max-width: 400px;
            border-radius: 8px;
            box-shadow: 0 0 15px rgba(0, 196, 180, 0.3);
        }
        button {
            background: #00c4b4;
            color: #1a1a1a;
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 1.1rem;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            margin: 15px 0;
        }
        button:hover {
            transform: scale(1.05);
            box-shadow: 0 0 15px rgba(0, 196, 180, 0.7);
        }
        #thumbnail {
            margin-top: 10px;
            max-width: 150px;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 196, 180, 0.3);
            display: none; /* Hidden until first snap */
        }
        #result {
            margin-top: 20px;
            font-size: 1.1rem;
            color: #ffffff;
            background: #333333;
            padding: 15px;
            border-radius: 8px;
            line-height: 1.5;
        }
        @media (max-width: 600px) {
            h1 { font-size: 1.5rem; padding: 12px; }
            p { font-size: 0.9rem; }
            button { font-size: 1rem; padding: 10px 20px; }
            #thumbnail { max-width: 120px; }
        }
    </style>
    <!-- Load TensorFlow.js library -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <!-- Load MobileNet model (for demo; replace with your custom model) -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@latest"></script>
</head>
<body>
    <div class="container">
        <h1><span>Denman Island Artifact Scanner</span></h1>
        <p>Point your camera at an exhibit item and snap for epic lore. Mobile magic awaits!</p>
        <video id="video" autoplay playsinline aria-label="Live camera feed for artifact scanning"></video>
        <br>
        <button id="snap" aria-label="Capture photo and identify artifact">Snap & Identify</button>
        <img id="thumbnail" alt="Captured artifact thumbnail" aria-hidden="true">
        <div id="result" aria-live="polite"></div>
    </div>

    <script>
        // Step 1: Access the camera (prefers rear on mobile for artifact scanning)
        async function setupCamera() {
            const video = document.getElementById('video');
            const constraints = {
                video: { facingMode: 'environment' }  // 'environment' for back camera; 'user' for front
            };
            try {
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
            } catch (err) {
                console.error('Camera access denied or error:', err);
                alert('Oops! Camera access needed for scanning. Check permissions?');
            }
        }

        // Step 2: Load the ML model (MobileNet for demo; see below for custom)
        let model;
        async function loadModel() {
            model = await mobilenet.load();  // Pre-trained MobileNet (classifies 1000 common objects)
            console.log('Model loaded and ready to geek out!');
        }

        // Step 3: Capture image from video, show thumbnail, and classify
        document.getElementById('snap').addEventListener('click', async () => {
            const video = document.getElementById('video');
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);

            // Display thumbnail
            const thumbnail = document.getElementById('thumbnail');
            thumbnail.src = canvas.toDataURL('image/jpeg');
            thumbnail.style.display = 'block'; // Show thumbnail

            // Run classification
            const predictions = await model.classify(canvas);
            displayResult(predictions);
        });

        // Step 4: Display result (mock database lookup; replace with your artifact info)
        function displayResult(predictions) {
            const resultDiv = document.getElementById('result');
            if (predictions.length > 0) {
                const topPrediction = predictions[0];
                // Mock artifact database (keyed by className; in real life, use Firebase or JSON)
                const artifactInfo = {
                    'vase': 'This ancient vase from 500 BC holds secrets of island pottery. Fun fact: It once stored mermaid tears!',
                    'teapot': 'Behold the enchanted teapot! Brewed elixirs for weary sailors. (Okay, mostly tea.)',
                    // Add more for your artifacts...
                    'default': `Hmm, looks like a ${topPrediction.className} with ${Math.round(topPrediction.probability * 100)}% confidence. Not in our collection? Snap again!`
                };
                resultDiv.innerHTML = artifactInfo[topPrediction.className] || artifactInfo['default'];
            } else {
                resultDiv.innerHTML = 'No predictions? Try better lighting, you shadowy detective!';
            }
        }

        // Initialize everything
        async function init() {
            await setupCamera();
            await loadModel();
        }
        init();
    </script>
</body>
</html>
